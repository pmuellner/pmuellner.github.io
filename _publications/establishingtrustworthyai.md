---
title: "Establishing and evaluating trustworthy AI: overview and research challenges"
authors: "Dominik Kowald, Sebastian Scher, Viktoria Pammer-Schindler, Peter Müllner, Kerstin Waxnegger, Lea Demelius, Angela Fessl, Maximilian Toller, Inti Gabriel Mendoza Estrada, Ilija Simic, Vedran Sabol, Andreas Trügler, Eduardo Veas, Roman Kern, Tomislav Nad, Simone Kopeinik"
collection: publications
permalink: /publication/establishingtrustworthyai
excerpt: "In this paper, we synthesize existing conceptualizations of trustworthy AI along six requirements: (1) human agency and oversight, (2) fairness and non-discrimination, (3) transparency and explainability, (4) robustness and accuracy, (5) privacy and security, and (6) accountability. For each one, we provide a definition, describe how it can be established and evaluated, and discuss requirement-specific research challenges. Finally, we conclude this analysis by identifying overarching research challenges across the requirements with respect to (1) interdisciplinary research, (2) conceptual clarity, (3) context-dependency, (4) dynamics in evolving systems, and (5) investigations in real-world contexts."
date: 2024-11-29
venue: 'Frontiers in Big Data (Sec. Machine Learning and Artificial Intelligence)'
paperurl: 'http://pmuellner.github.io/files/establishingtrustworthyai.pdf'
citation: ' Kowald D, Scher S, Pammer-Schindler V, Müllner P, Waxnegger K, Demelius L, Fessl A, Toller M, Mendoza Estrada IG, Šimić I, Sabol V, Trügler A, Veas E, Kern R, Nad T and Kopeinik S (2024) Establishing and evaluating trustworthy AI: overview and research challenges. Front. Big Data 7:1467222. doi: 10.3389/fdata.2024.1467222'

---
Artificial intelligence (AI) technologies (re-)shape modern life, driving innovation in a wide range of sectors. However, some AI systems have yielded unexpected or undesirable outcomes or have been used in questionable manners. As a result, there has been a surge in public and academic discussions about aspects that AI systems must fulfill to be considered trustworthy. In this paper, we synthesize existing conceptualizations of trustworthy AI along six requirements: (1) human agency and oversight, (2) fairness and non-discrimination, (3) transparency and explainability, (4) robustness and accuracy, (5) privacy and security, and (6) accountability. For each one, we provide a definition, describe how it can be established and evaluated, and discuss requirement-specific research challenges. Finally, we conclude this analysis by identifying overarching research challenges across the requirements with respect to (1) interdisciplinary research, (2) conceptual clarity, (3) context-dependency, (4) dynamics in evolving systems, and (5) investigations in real-world contexts. Thus, this paper synthesizes and consolidates a wide-ranging and active discussion currently taking place in various academic sub-communities and public forums. It aims to serve as a reference for a broad audience and as a basis for future research directions.